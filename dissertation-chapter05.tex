%
% SECTION
%
\section{Theoretical Maximum Performance}

The Raspberry Pi 4 Model B is based on the Broadcom BCM2711 \emph{System on a Chip} (SoC). The BCM2711 includes four Arm Cortex-A72 cores clocked at 1.5 GHz.

Each core of the Arm Cortex-A72 implements the 64-bit Armv8-A ISA (Instruction Set Architecture). This instruction set includes Advanced SIMD instructions which operate on a single 128-bit SIMD pipeline. This pipeline can conduct two 64-bit double precision \emph{floating point operations} per clock cycle.  

A \emph{fused multiply-add} (FMA) instruction implements a \emph{multiplication} followed by an \emph{add} in a single instruction. The main purpose of FMA instructions is to improve result accuracy by conducting a single rounding operation on completion of both the \emph{multiplication} and \emph{add} operations. A single FMA instruction conducts two \emph{floating point operations} per clock cycle. 

The theoretical maximum performance of a single Aerin Cluster node, $R_{peak}$, is therefore:

\begin{align}
R_{peak} &= 4 \textrm{ cores} \times 1.5 \textrm{ GHz} \times 2 \textrm{ doubles} \times 2 \textrm{ FMA}\\
&= 24 \textrm{ Gflops}
\end{align}

This $R_{peak}$ of 24 Gflops is only achievable, continuously, if every instruction in a program is an FMA instruction, and the program data is aligned in memory appropriately for efficient access. This obviously cannot be the case, since a program will consist of at least some instructions to  load data from memory and store results back in memory, and these are not FMA instructions. Therefore, $R_{peak}$ is very much a theoretical maximum performance. 

The theoretical maximum performance of the Aerin Cluster as a whole is therefore:

\begin{align}
R_{peak} &= 8 \textrm{ nodes} \times 24 \textrm{ Gflops}\\
&= 192 \textrm{ Gflops}
\end{align}

For maximum performance, the HPL benchmark requires a problem size which utilises 100\% of memory. But, because the operating system requires memory, this is never fully achievable. 

\begin{figure}[h]
	\centering	
	\includegraphics[width=0.95\textwidth]{screenshot-memory.png}
	\caption{\textbf{Available Memory}. Output from \texttt{dmesg | grep Memory} indicates the memory usage by the Linux kernel, and the memory available to applications and benchmarks}
\end{figure}

As can be seen in Figure 5.1, 3.6 GB of memory (3,783,864 KB) is available to applications and benchmarks per node. This equates to 90\% of the total 4 GB (4,194,304 KB) per node. Any transient use of more than 90\% of memory will result in memory pages being swapped to permanent storage, which will negatively impact benchmark performance.

Therefore, for the HPL baseline benchmarks, 80\% of available memory was chosen for the problem size. This is also the amount suggested as an initial \emph{good guess} in HPL Frequently Asked Questions \cite{hpl-faq}.

The above necessarily results in the baseline performance only being able to achieve 80\% of $R_{peak}$, at best. This is 4.8 Gflops for a single core, 19.2 Gflops for a single node, 38.4 Gflops for two nodes, and 153.6 Gflops for the 8 node cluster. These values are indicated on the HPL baseline performance plots.


%
% SECTION
%
\section{HPL Baseline}

Detailed instructions on how to install the HPL benchmark software, and how to run the HPL benchmark are included in the project repository wiki.

To establish \emph{baseline} performance, the HPL benchmark was run using the default Ubuntu 20.04 LTS 64-bit packages, and without any system or network tuning.

Baseline performance was investigated for the single core, single node, two node and whole cluster configurations.


%
% SUB SECTION
%
\subsection{HPL 1 Core Baseline}

The purpose of this investigation is to determine the performance of a single core running a single \verb|xhpl| process, with the single core having exclusive access to the shared L2 cache. 

As discussed in the previous section, the HPL problem size is restricted to 80\% of available memory. In the case, 80\% of a single node's 4 GB. Using values of block size NB from 32 to 256, as suggested by HPL Frequently Asked Questions \cite{hpl-faq}, and using equation 3.9 to ensure the problem size N is an integer multiple of NB, results in Table 5.1 of NB and N combinations.

\begin{table}[H]
\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
		\hline
		\textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} \\ 
		\hline
		32 & 18528 &  80 & 18480 & 128 & 18432 & 176 & 18480 & 224 & 18368 \\ 
		40 & 18520 &  88 & 18480 & 136 & 18496 & 184 & 18400 & 232 & 18328 \\ 
 		48 & 18528 &  96 & 18528 & 144 & 18432 & 192 & 18432 & 240 & 18480 \\
		56 & 18536 & 104 & 18512 & 152 & 18392 & 200 & 18400 & 248 & 18352 \\ 
 		64 & 18496 & 112 & 18480 & 160 & 18400 & 208 & 18512 & 256 & 18432 \\
		72 & 18504 & 120 & 18480 & 168 & 18480 & 216 & 18360 &   - &     - \\ 
 		\hline
	\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{1 Core NB and N Combinations.} Block size NB and problem size N combinations for NB between 32 and 256 using 80\% of 4 GB of memory.}
\end{table}

The benchmark results are plotted in Figure 5.2.

\begin{figure}[H]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmpi_gflops_vs_nb_1_core_80_percent_memory.pdf}
		\caption{Pure OpenMPI}
		\label{fig:subim1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmp_gflops_vs_nb_1_core_80_percent_memory.pdf}
		\caption{Hybrid OpenMPI/OpenMP}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{HPL 1 Core $\mathbf{R_{max}}$ versus NB.}}
\label{fig:image2}
\end{figure}

Note: There is no actual benefit in using a hybrid OpenMPI/OpenMP topology for a single core running a single \verb|xhpl| process, as only a single thread is used. However, to ensure similar results were achieved, both pure OpenMPI and hybrid OpenMPI/OpenMP topologies were benchmarked.

%
% SUB SUB SECTION
%
\subsubsection{Observations}

As expected, there is no significant performance difference between the two topologies for both OpenBLAS and BLIS.

OpenBLAS and BLIS both attain 80\% $R_{peak}$. Without competition from additional cores for access to the L2 cache, both libraries are able to efficiently stream data from main memory, through the L1 and L2 caches, to the core registers. 


%
% SUB SECTION
%
\subsection{HPL 1 Node Baseline}

The purpose of this investigation is to determine the performance of the 4 cores of a single node. In this case each core shares the L2 cache with the other cores, so less L2 data will be available per core. This should result in more L2 \emph{cache misses} requiring a \emph{cache load} from main memory. It is therefore anticipated that this will result in a performance reduction, per core, compared to the single core case.

As per the single core benchmark, the HPL problem size is restricted to 80\% of available memory. Again, this is 80\% of a single node's 4 GB. This results in the same NB and N combinations as the single core benchmark of Table 5.1.

The benchmark results are plotted in Figure 5.3. 

%
% SUB SUB SECTION
%
\subsubsection{Observations}

As anticipated, there is indeed a reduction in performance per core. The 80\% of $R_{peak}$, 19.2 Gflops for the combined 4 cores, in no longer attained.

The pure OpenMPI topology attains an $R_{max}$ of 15.219 Gflops using the BLIS library with an NB of 184.

The hybrid OpenMPI/OpenMP topology attains an $R_{max}$ of 16.299 Gflops using the BLIS library with an NB of 232.

The above represent 79.27\% and 84.89\% of 80\% $R_{peak}$, respectively.

\begin{figure}[H]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmpi_gflops_vs_nb_1_node_80_percent_memory.pdf}
		\caption{Pure OpenMPI}
		\label{fig:subim1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmp_gflops_vs_nb_1_node_80_percent_memory.pdf}
		\caption{Hybrid OpenMPI/OpenMP}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{HPL 1 Node $\mathbf{R_{max}}$ versus NB.}}
\label{fig:image2}
\end{figure}


%
% SUB SECTION
%
\subsection{HPL 2 Node Baseline}

The purpose of this baseline is to determine the performance of 2 nodes. Now, each core not only has to share access to the L2 cache, but the cache will be loaded with data less frequently due to network delays and competition between the nodes for access to network. It is therefore anticipated that this will result in a performance reduction, per node, compared to the single node case.

For this baseline the HPL problem size is restricted to 80\% of 2 nodes combined memory, 80\% of 8 GB. This results in the NB and N combinations in Table 5.2.

\begin{table}[H]
\begin{center}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
		\hline
		\textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} & \textbf{NB} & \textbf{N} \\ 
		\hline
		32 & 26208 &  80 & 26160 & 128 & 26112 & 176 & 26048 & 224 & 26208 \\ 
		40 & 26200 &  88 & 26136 & 136 & 26112 & 184 & 26128 & 232 & 25984 \\ 
 		48 & 26208 &  96 & 26208 & 144 & 26208 & 192 & 26112 & 240 & 26160 \\
		56 & 26208 & 104 & 26208 & 152 & 26144 & 200 & 26200 & 248 & 26040 \\ 
 		64 & 26176 & 112 & 26208 & 160 & 26080 & 208 & 26208 & 256 & 26112 \\
		72 & 26208 & 120 & 26160 & 168 & 26208 & 216 & 26136 &   - &     - \\ 
 		\hline
	\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{2 Node NB and N Combinations.}  Block size NB and problem size N combinations for NB between 32 and 256 using 80\% of 8 GB of memory}
\end{table}

The benchmark results are plotted in Figure 5.4

\begin{figure}[]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmpi_gflops_vs_nb_2_node_80_percent_memory.pdf}
		\caption{Pure OpenMPI}
		\label{fig:subim1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmp_gflops_vs_nb_2_node_80_percent_memory.pdf}
		\caption{Hybrid OpenMPI/OpenMP}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{HPL 2 Node $\mathbf{R_{max}}$ versus NB.}}
\label{fig:image2}
\end{figure}

%
% SUB SUB SECTION
%
\subsubsection{Observations}

For 2 nodes 80\% $R_{peak}$ is 38.4 Gflops.

The pure OpenMPI topology attains an $R_{max}$ of 27.814 Gflops using the BLIS library with an NB of 168.

The hybrid OpenMPI/OpenMP topology attains an $R_{max}$ of 30.312 Gflops using the BLIS library with an NB of 200.

The above represent 72.43\% and 78.94\% of 80\% $R_{peak}$, respectively.

Compared to the single node case, 2 node performance is reduced by 17.8\% for the pure OpenMPI topology, and 15.5\% for the hybrid OpenMPI/OpenMP topology, due to inter-node MPI process communication and network overhead.


%
% SUB SECTION
%
\subsection{HPL Whole Cluster Baseline}

This whole cluster baseline uses the values of NB from the 2 node baseline which attained optimum performance.

The benchmark results are presented in Tables 5.3 and 5.4. In these tables, for each node count, there is also a value of $R_{max}$ for each processor grid shape. This is because within each N, NB, P and Q parameter set, there are also HPL parameters which have a lesser effect on performance. $R_{max}$ is the maximum observed performance for each set of N, NB, P and Q parameters.

The highest value of $R_{max}$ for each node count is then plotting in Figure 5.5.


\begin{table}[H]
\begin{center}
\begin{tabular}{ |l|c|c|c|c|c|c| } 
\hline
\textbf{BLAS Library} & \textbf{Nodes} & \textbf{N} & \textbf{NB} & \textbf{P} & \textbf{Q} & \textbf{$\mathbf{R_{max}}$} \textbf{(Gflops)} \\ 
\hline
OpenBLAS Serial & 3 & 32040 & 120 & 1 & 12 & 3.3720e+01 \\ 
                & 3 & 32040 & 120 & 2 &  6 & 3.1946e+01 \\
                & 3 & 32040 & 120 & 3 &  4 & 3.3844e+01 \\
                \cline{2-7} 
                & 4 & 36960 & 120 & 1 & 16 & 4.7742e+01 \\ 
                & 4 & 36960 & 120 & 2 &  8 & 4.9390e+01 \\ 
                \cline{2-7} 
                & 5 & 41400 & 120 & 1 & 20 & 5.6513e+01 \\ 
                & 5 & 41400 & 120 & 2 & 10 & 5.6038e+01 \\ 
                & 5 & 41400 & 120 & 4 &  5 & 5.5649e+01 \\ 
                \cline{2-7} 
                & 6 & 45360 & 120 & 1 & 24 & 6.8392e+01 \\ 
                & 6 & 45360 & 120 & 2 & 12 & 7.3856e+01 \\ 
                & 6 & 45360 & 120 & 3 &  8 & 6.9952e+01 \\ 
                \cline{2-7} 
                & 7 & 48960 & 120 & 1 & 28 & 7.8248e+01 \\ 
                & 7 & 48960 & 120 & 2 & 14 & 8.1017e+01 \\ 
                & 7 & 48960 & 120 & 4 &  7 & 8.1433e+01 \\ 
                \cline{2-7} 
                & 8 & 52320 & 120 & 1 & 32 & 8.6787e+01 \\ 
                & 8 & 52320 & 120 & 2 & 16 & 9.5517e+01 \\ 
                & 8 & 52320 & 120 & 4 &  8 & 9.5525e+01 \\ 
\hline
OpenBLAS OpenMP & 3 & 32032 & 88 & 1 & 3 & 3.7842e+01 \\ 
                \cline{2-7} 
                & 4 & 37048 & 88 & 1 & 4 & 4.8657e+01 \\ 
                \cline{2-7} 
                & 5 & 41448 & 88 & 1 & 5 & 6.0428e+01 \\ 
                \cline{2-7} 
                & 6 & 45320 & 88 & 1 & 6 & 6.8713e+01 \\ 
                & 6 & 45320 & 88 & 2 & 3 & 7.3722e+01 \\ 
                \cline{2-7} 
                & 7 & 49016 & 88 & 1 & 7 & 7.8712e+01 \\ 
                \cline{2-7} 
                & 8 & 52360 & 88 & 1 & 8 & 9.4245e+01 \\ 
                & 8 & 52360 & 88 & 2 & 4 & 9.6630e+01 \\ 
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPL Whole Cluster OpenBLAS Baseline.}}
\end{table}


\begin{table}
\begin{center}
\begin{tabular}{ |l|c|c|c|c|c|c| } 
\hline
\textbf{BLAS Library} & \textbf{Nodes} & \textbf{N} & \textbf{NB} & \textbf{P} & \textbf{Q} & \textbf{$\mathbf{R_{max}}$ (Gflops)} \\ 
\hline
BLIS Serial     & 3 & 32088 & 168 & 1 & 12 & 3.9005e+01 \\ 
                & 3 & 32088 & 168 & 2 &  6 & 3.9050e+01 \\ 
                & 3 & 32088 & 168 & 3 &  4 & 3.8958e+01 \\ 
                \cline{2-7} 
                & 4 & 36960 & 168 & 1 & 16 & 4.9694e+01 \\ 
                & 4 & 36960 & 168 & 2 &  8 & 5.4268e+01\\ 
                \cline{2-7} 
                & 5 & 41328 & 168 & 1 & 20 & 5.5398e+01 \\ 
                & 5 & 41328 & 168 & 2 & 10 & 6.5226e+01 \\ 
                & 5 & 41328 & 168 & 4 &  5 & 6.2356e+01 \\ 
                \cline{2-7} 
                & 6 & 45360 & 168 & 1 & 24 & 7.0278e+01 \\ 
                & 6 & 45360 & 168 & 2 & 12 & 7.9685e+01 \\ 
                & 6 & 45360 & 168 & 3 &  8 & 7.5475e+01 \\ 
                \cline{2-7} 
                & 7 & 48888 & 168 & 1 & 28 & 8.0168e+01 \\ 
                & 7 & 48888 & 168 & 2 & 14 & 8.7571e+01 \\ 
                & 7 & 48888 & 168 & 4 &  7 & 8.6035e+01 \\ 
                \cline{2-7} 
                & 8 & 52416 & 168 & 1 & 32 & 9.1148e+01 \\ 
                & 8 & 52416 & 168 & 2 & 16 & 1.0341e+02 \\ 
                & 8 & 52416 & 168 & 4 &  8 & 1.0190e+02 \\ 
\hline
BLIS OpenMP     & 3 & 32000 & 200 & 1 & 3 & 3.5132e+01 \\ 
                \cline{2-7} 
                & 4 & 37000 & 200 & 1 & 4 & 4.6953e+01 \\ 
                \cline{2-7} 
                & 5 & 41400 & 200 & 1 & 5 & 6.2550e+01 \\ 
                \cline{2-7} 
                & 6 & 45400 & 200 & 1 & 6 & 6.7204e+01 \\ 
                & 6 & 45400 & 200 & 2 & 3 & 7.2585e+01 \\ 
                \cline{2-7} 
                & 7 & 49000 & 200 & 1 & 7 & 8.1255e+01 \\ 
                \cline{2-7} 
                & 8 & 52400 & 200 & 1 & 8 & 9.1180e+01 \\ 
                & 8 & 52400 & 200 & 2 & 4 & 1.0041e+02 \\ 
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPL Whole Cluster BLIS Baseline.}}
\end{table}


\begin{figure}[H]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmpi_gflops_vs_nodes_80_percent_memory.pdf}
		\caption{Pure OpenMPI}
		\label{fig:subim1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{openmp_gflops_vs_nodes_80_percent_memory.pdf}
		\caption{Hybrid OpenMPI/OpenMP}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{HPL $\mathbf{R_{max}}$ versus Node Count.}}
\label{fig:image2}
\end{figure}


%
% SUB SECTION
%
\subsection{Observations}

Performance scales linearly with node count.

Where there are multiple P x Q processor grid combinations available, optimum performance is achieved with a P x Q grid which is not \emph{flat}. For example, 2 x 16 and 4 x 8 grids performs better than a 1 x 32 grid. This is consistent with HPL Frequency Asked Questions \cite{hpl-faq}, and is related to the computation to communication ratio of the cluster.

For a high performance network such as Infiniband, optimum performance is expected to be achieved with the most \emph{square} P x Q grid. In the previous example, this would be the 4 x 8 grid. Ethernet is not a high performance network, in HPC terms, and optimum performance is expected to be achieved from less \emph{square}, but not \emph{flat} processor, grid.

A combination of \emph{square} and \emph{less square} processor grids produced optimum performance for the Aerin Cluster. This is attributable to the good network performance of the Raspberry Pi 4, which can utilise almost the full 1 Gigabit of available bandwidth. 

For 8 nodes, 80\% $R_{peak}$ is 153.6 Gflops.

For 8 nodes, the highest $R_{max}$ of 103.41 Gflops was observed using the BLIS Serial library with an NB of 168, and a P x Q grid of 2 x 16. This is 67.32\% of the maximum theoretical performance using 80\% of memory.



%
% SECTION
%
\section{HPCC Baseline}

The HPCC benchmark suite was run using all 8 nodes of the Aerin Cluster to obtain a whole cluster baseline.

Recall from Chapter 2, \emph{single} indicates the benchmark is run on a single randomly selected node, \emph{star} indicates the benchmark in run independently on all nodes, and \emph{global} indicates the benchmark is run using all nodes in a coordinated manner.

The results for each benchmark are presented below.


%
% SUB SECTION
%
\subsection{HPL}

HPL is included in HPCC. The performance results when running HPL as part of HPCC were similar to those when running HPL as a standalone benchmark.


%
% SUB SECTION
%
\subsection{DGEMM}

\begin{table}[H]
\begin{center}
\begin{tabular}{ |l|l| } 
\hline
\textbf{BLAS Library} & \textbf{Results} \\ 
\hline
OpenBLAS Serial & DGEMM\_N=5339 \\
                & StarDGEMM\_Gflops=3.59743 \\
                & SingleDGEMM\_Gflops=4.91086 \\
\hline
OpenBLAS OpenMP & DGEMM\_N=10687 \\
                & StarDGEMM\_Gflops=14.4261 \\
                & SingleDGEMM\_Gflops=14.426 \\
\hline
BLIS Serial     & DGEMM\_N=5349 \\
                & StarDGEMM\_Gflops=3.02439 \\
                & SingleDGEMM\_Gflops=4.95418 \\
\hline
BLIS OpenMP     & DGEMM\_N=10695 \\
                & StarDGEMM\_Gflops=16.3355 \\
                & SingleDGEMM\_Gflops=15.2042 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC DGEMM.}}
\end{table}

The DGEMM benchmark measures the performance of double precision real \emph{matrix-matrix multiplication}. The benchmark results are presented in Table 5.5.

For the single-threaded serial versions of the OpenBLAS and BLIS libraries the cluster consists of 32 processing cores. The \verb|SingleDGEMM_Gflops| results are per core.

For the multi-threaded OpenMP versions of the libraries, the cluster consists of 8 processing nodes. The \verb|SingleDGEMM_Gflops| results are per node.

\subsubsection{Observations}

The results are consistent with the HPL benchmarks, which spends approximately 87\% of the benchmark run time in the BLAS \verb|dgemm| subroutine. 

Of note  is the \emph{jitter} between the \emph{single} and \emph{star} results, particularly the OpenBLAS Serial and BLIS Serial results. This is explained by the fact that a \emph{single} randomly selected core running the benchmark has exclusive access to the L2 cache. The \emph{single} result is consistent with 1 Core Baseline results. In the \emph{star} case, all cores on each node are running the benchmark and have to share access to the L2 cache. The \emph{star} result is consistent with the 1 Node Baseline results.


%
% SUB SECTION
%
\subsection{STREAM}

The STREAM benchmark measures sustained memory bandwidth by performing four vector operations, \emph{Copy}, \emph{Scale}, \emph{Sum} and \emph{Triad}, on vectors which are at least 4 times the size of the L2 cache. This ensures the benchmark is measuring main memory access performance.

For the purposes of measuring pure memory bandwidth the \emph{Copy} operation is the most appropriate. This measures the copying of a vector from one memory location to another, without any computation on the vector data.   

The STREAM benchmark results are presented in table 5.6.

\begin{table}[]
\begin{center}
\begin{tabular}{ |l|l| } 
\hline
\textbf{BLAS Library} & \textbf{Results} \\ 
\hline
OpenBLAS Serial & STREAM\_VectorSize=28514400 \\
                & STREAM\_Threads=1 \\
                & StarSTREAM\_Copy=0.92926 \\
                & StarSTREAM\_Scale=0.979969 \\
                & StarSTREAM\_Add=0.902324 \\
                & StarSTREAM\_Triad=0.899619 \\
                & SingleSTREAM\_Copy=5.36868 \\
                & SingleSTREAM\_Scale=5.41684 \\
                & SingleSTREAM\_Add=4.75638 \\
                & SingleSTREAM\_Triad=4.75692 \\
\hline
OpenBLAS OpenMP & STREAM\_VectorSize=114232066 \\
                & STREAM\_Threads=1 \\
                & StarSTREAM\_Copy=4.76068 \\
                & StarSTREAM\_Scale=5.44287 \\
                & StarSTREAM\_Add=4.51713 \\
                & StarSTREAM\_Triad=4.53621 \\
                & SingleSTREAM\_Copy=5.47035 \\
                & SingleSTREAM\_Scale=5.46963 \\
                & SingleSTREAM\_Add=4.87128 \\
                & SingleSTREAM\_Triad=4.89569 \\
\hline
BLIS Serial     & STREAM\_VectorSize=28619136 \\
                & STREAM\_Threads=1 \\
                & StarSTREAM\_Copy=0.943137 \\
                & StarSTREAM\_Scale=0.989024 \\
                & StarSTREAM\_Add=0.910843 \\
                & StarSTREAM\_Triad=0.909211 \\
                & SingleSTREAM\_Copy=4.72341 \\
                & SingleSTREAM\_Scale=4.21768 \\
                & SingleSTREAM\_Add=3.90016 \\
                & SingleSTREAM\_Triad=3.94385 \\
\hline
BLIS OpenMP     & STREAM\_VectorSize=114406666 \\
                & STREAM\_Threads=1 \\
                & StarSTREAM\_Copy=5.05861 \\
                & StarSTREAM\_Scale=5.39591 \\
                & StarSTREAM\_Add=4.66044 \\
                & StarSTREAM\_Triad=4.6751 \\
                & SingleSTREAM\_Copy=5.41884 \\
                & SingleSTREAM\_Scale=5.45544 \\
                & SingleSTREAM\_Add=4.80613 \\
                & SingleSTREAM\_Triad=4.81397 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC STREAM.}}
\end{table}


\subsubsection{Observations}

As noted previously, the \emph{single} OpenBLAS Serial and BLIS Serial benchmarks relate to single core. And as indicated in the results, the maximum observed single core memory bandwidth is approximately 5.4 MB/s. The \emph{star} serial results of approximately 0.94 GB/s need to be factored by the node count to measure the whole node main memory bandwidth, which is then the same order of magnitude but reduced due to L2 cache collisions. 

For bandwidth measurement, the STREAM benchmark counts both the memory read and the memory write as a memory movement. This differs from most memory bandwidth benchmarks in which the read and write from one memory location to another count as a single memory movement. Therefore, for the \emph{Copy} operation, the benchmark results needs to be factored by 0.5 to align with other benchmarks and memory specifications.

For three out of the 4 BLAS library combinations, the observed \emph{Copy} vector operation bandwidth is approximately 5.4 GB/s.

The Raspberry Pi 4 Model B is equipped with LPDDR4–3200 SDRAM (Low-Power Double Data Rate Static DRAM), with a maximum data transfer rate of 3200 MB/s (3.2 GB/s).

The observed benchmark \emph{Copy} performance of 5.4 GB/s, when factored by 0.5 is 2.7 GB/s. This is 80\% of the maximum data transfer rate. This suggests that the Raspberry Pi 4 Model B is making good use of the available memory bandwidth. 



%
% SUB SECTION
%
\subsection{PTRANS}

PTRANS is a \emph{global} benchmark which implements the transpose of a large matrix in memory using the cluster nodes operating in parallel. The main purpose of this benchmark is to test inter-node communication performance.

The value of NB was selected to be optimum value from the 2 Node Baseline, with the corresponding value of N equating to 40\% of total memory. Since this not a computation benchmark, 40\% memory usage is sufficient to test inter-node communication without excessive run time. 



\begin{table}[]
\begin{center}
\begin{tabular}{ |l|l| } 
\hline
\textbf{BLAS Library} & \textbf{Results} \\
\hline
OpenBLAS Serial & PTRANS\_GBs=0.465891 \\
                & PTRANS\_n=26160 \\ 
                & PTRANS\_nb=120 \\
                & PTRANS\_nprow=1 \\
                & PTRANS\_npcol=32 \\
\hline
OpenBLAS OpenMP & PTRANS\_GBs=0.616885 \\
                & PTRANS\_n=26180 \\
                & PTRANS\_nb=88 \\
                & PTRANS\_nprow=2 \\
                & PTRANS\_npcol=4 \\
\hline
BLIS Serial     & PTRANS\_GBs=0.483766 \\
                & PTRANS\_n=26208 \\
                & PTRANS\_nb=168 \\
                & PTRANS\_nprow=1 \\
                & PTRANS\_npcol=32 \\
\hline
BLIS OpenMP     & PTRANS\_GBs=0.637484 \\
                & PTRANS\_n=26200 \\
                & PTRANS\_nb=200 \\
                & PTRANS\_nprow=2 \\
                & PTRANS\_npcol=4 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC PTRANS.}}
\end{table}


\subsubsection{Observations}

Both the OpenBLAS and BLIS serial benchmark runs produce similar results. Similarly, both OpenMP benchmark runs produce similar results. This is to be expected, since this benchmark is not testing BLAS library performance. The difference between the serial and OpenMP performance is related to the topology of the cluster, either a pure OpenMPI or hybrid OpenMPI/OpenMP topology.

With an average pure OpenMPI result of 0.475 GB/s, and a hybrid OpenMPI/OpenMP result of 0.627 GB/s, the inter-node communication performance is 32\% faster using the hybrid OpenMPI/OpenMP topology.

This result is to be expected, since the node count is 32 in the pure OpenMPI topology, but only 8 in the hybrid OpenMPI/OpenMP topology. Even though the amount of matrix data to be transposed remains the same, the inter-node communication is reduced. The inter-node messages may be larger, but there are fewer messages with less node addressing overhead, making the cluster network more efficient. 


%
% SUB SECTION
%
\subsection{Random Access}

The Random Access benchmark tests the integer update performance of a large array in memory. Random numbers generated from a normal distribution and the Linear Congruential Generator algorithm are used. The unit of the results is GUPs (\emph{GigaUpdates per Second}).

\begin{table}[]
\begin{center}
\begin{tabular}{ |l|l| } 
\hline
\textbf{BLAS Library} & \textbf{Results} \\ 
\hline
OpenBLAS Serial & MPIRandomAccess\_LCG\_N=2147483648 \\
                & MPIRandomAccess\_LCG\_GUPs=0.000642364 \\
                \cline{2-2} 
                & MPIRandomAccess\_N=2147483648 \\
                & MPIRandomAccess\_GUPs=0.000645338 \\
                \cline{2-2} 
                & RandomAccess\_LCG\_N=67108864 \\
                & StarRandomAccess\_LCG\_GUPs=0.00373175 \\
                & SingleRandomAccess\_LCG\_GUPs=0.00815537 \\
                \cline{2-2} 
                & RandomAccess\_N=67108864 \\
                & StarRandomAccess\_GUPs=0.00373372 \\
                & SingleRandomAccess\_GUPs=0.00837312 \\ 
\hline
OpenBLAS OpenMP & MPIRandomAccess\_LCG\_N=2147483648 \\
                & MPIRandomAccess\_LCG\_GUPs=0.000473649 \\
                \cline{2-2} 
                & MPIRandomAccess\_N=2147483648 \\
                & MPIRandomAccess\_GUPs=0.000477404 \\
                \cline{2-2} 
                & RandomAccess\_LCG\_N=268435456 \\
                & StarRandomAccess\_LCG\_GUPs=0.00580416 \\
                & SingleRandomAccess\_LCG\_GUPs=0.00582959 \\
                \cline{2-2} 
                & RandomAccess\_N=268435456 \\
                & StarRandomAccess\_GUPs=0.00614337 \\
                & SingleRandomAccess\_GUPs=0.00613214 \\
\hline
BLIS Serial     & MPIRandomAccess\_LCG\_N=2147483648 \\
                & MPIRandomAccess\_LCG\_GUPs=0.000644523 \\
                \cline{2-2} 
                & MPIRandomAccess\_N=2147483648 \\
                & MPIRandomAccess\_GUPs=0.00064675 \\
                \cline{2-2} 
                & RandomAccess\_LCG\_N=67108864 \\
                & StarRandomAccess\_LCG\_GUPs=0.00374527 \\
                & SingleRandomAccess\_LCG\_GUPs=0.00835127 \\
                \cline{2-2} 
                & RandomAccess\_N=67108864 \\
                & StarRandomAccess\_GUPs=0.00374741 \\
                & SingleRandomAccess\_GUPs=0.00820883 \\
\hline
BLIS OpenMP     & MPIRandomAccess\_LCG\_N=2147483648 \\
                & MPIRandomAccess\_LCG\_GUPs=0.000475485 \\
                \cline{2-2} 
                & MPIRandomAccess\_N=2147483648 \\
                & MPIRandomAccess\_GUPs=0.000476047 \\
                \cline{2-2} 
                & RandomAccess\_LCG\_N=268435456 \\
                & StarRandomAccess\_LCG\_GUPs=0.00580705 \\
                & SingleRandomAccess\_LCG\_GUPs=0.00578222 \\
                \cline{2-2} 
                & RandomAccess\_N=268435456 \\
                & StarRandomAccess\_GUPs=0.00614596 \\
                & SingleRandomAccess\_GUPs=0.00613275 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC Random Access.}}
\end{table}


\subsubsection{Observations}

For the \emph{global} benchmarks, the array size $N = 2,147,483,648$ represents 25\% of the cluster's total 32 GB of memory.

For the \emph{single} pure OpenMPI benchmarks, the array size $N = 67,108,864$ represents 25\% of 1 GB of memory. Each of the 4 cores of each node is allocated 1 GB of the total 4 GB of memory, and the array is selected to be 25\% of this.

And, for the \emph{single} hybrid OpenMPI/OpenMP benchmarks, the array size $N = 268,435,456$ represents 25\% of a single nodes's 4 GB of memory.

The above array sizes are determined by the benchmark and not selected by the user.

As expected, because this benchmark is not a test of computational performance, the pure OpenMPI topology performance is almost identical for both BLAS libraries. Similarly, the hybrid OpenMPI/OpenMP topology performance is almost identical for both BLAS libraries.

 


%
% SUB SECTION
%
\subsection{FFT}

The FFT benchmark...

\begin{table}[h]
\begin{center}
\begin{tabular}{ |l|c| } 
\hline
\textbf{BLAS Library} & \textbf{Results} \\ 
\hline
OpenBLAS Serial & Global Vector size: 268435456\\
                & Global Gflops:      1.569 \\
                \cline{2-2} 
                & Star Vector size:   16777216 \\
                & Star Min Gflops:    0.251138 \\
                & Star Avg Gflops:    0.314311 \\ 
                & Star Min Gflops:    0.335671 \\
                \cline{2-2}
                & Single Gflops:      0.494388 \\
\hline
OpenBLAS OpenMP & Global Vector size: 268435456 \\
                & Global Gflops:      1.347 \\
                \cline{2-2} 
                & Star Vector size:   67108864 \\
                & Star Min Gflops:    0.314714 \\
                & Star Avg Gflops:    0.344635 \\ 
                & Star Min Gflops:    0.375736 \\
                \cline{2-2}
                & Single Gflops:      0.532823 \\
\hline
BLIS Serial     & Global Vector size: 268435456 \\
                & Global Gflops:      1.563 \\
                \cline{2-2} 
                & Star Vector size:   16777216 \\
                & Star Min Gflops:    0.252763 \\
                & Star Avg Gflops:    0.312753 \\ 
                & Star Min Gflops:    0.344300 \\
                \cline{2-2}
                & Single Gflops:      0.515476\\
\hline
BLIS OpenMP     & Global Vector size: 268435456 \\
                & Global Gflops:      1.313 \\
                \cline{2-2} 
                & Star Vector size:   67108864 \\
                & Star Min Gflops:    0.315112 \\
                & Star Avg Gflops:    0.329216 \\ 
                & Star Min Gflops:    0.344110 \\
                \cline{2-2}
                & Single Gflops:      0.439117 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC FFT.}}
\end{table}


\subsubsection{Observations}

The...


%
% SUB SECTION
%
\subsection{Network Bandwidth and Latency}

The Network Bandwidth and Latency benchmark measures the time to send MPI messages between cluster processes. Latency is measured using 8 byte messages, and bandwidth is measured using 2,000,000 byte messages.

The major benchmark results are presented in table 5.10.

\begin{table}[h]
\begin{center}
\begin{tabular}{ |c| } 
\hline
\textbf{OpenBLAS Serial} \\ 
\hline
Max Ping Pong Latency:                 0.189604 msecs \\
Randomly Ordered Ring Latency:         0.192830 msecs \\
Min Ping Pong Bandwidth:             107.306358 MB/s \\
Naturally Ordered Ring Bandwidth:     61.385709 MB/s \\
Randomly  Ordered Ring Bandwidth:     16.907255 MB/s \\
\hline
\textbf{OpenBLAS OpenMP} \\ 
\hline
Max Ping Pong Latency:                 0.099864 msecs \\
Randomly Ordered Ring Latency:         0.075013 msecs \\
Min Ping Pong Bandwidth:             112.574381 MB/s \\
Naturally Ordered Ring Bandwidth:     70.511474 MB/s \\
Randomly  Ordered Ring Bandwidth:     73.119334 MB/s \\
\hline
\textbf{BLIS Serial} \\ 
\hline
Max Ping Pong Latency:                 0.191411 msecs \\
Randomly Ordered Ring Latency:         0.189172 msecs \\
Min Ping Pong Bandwidth:             107.075234 MB/s \\
Naturally Ordered Ring Bandwidth:     51.395031 MB/s \\
Randomly  Ordered Ring Bandwidth:     16.492559 MB/s \\
\hline
\textbf{BLIS OpenMP} \\ 
\hline
Max Ping Pong Latency:                 0.101356 msecs \\
Randomly Ordered Ring Latency:         0.070292 msecs \\
Min Ping Pong Bandwidth:             112.788813 MB/s \\
Naturally Ordered Ring Bandwidth:     99.948389 MB/s \\
Randomly  Ordered Ring Bandwidth:     72.585888 MB/s \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPCC Network Bandwidth and Latency.}}
\end{table}

The BLAS libraries are not used, but the results for all four library combinations are included for consistency with other benchmarks results.

A clear distinction needs to be made between Gigabits and Gigabytes/Megabytes. Using the standard \emph{byte} of 8 bits, 1 Gigabits per second (1 Gb/s) is 125 Megabytes per second (125 MB/s). This is the theoretical maximum bandwidth of the Raspberry Pi 4's Gigabit Ethernet interface.


\subsubsection{Observations}

The benchmark results are specified in Megabytes per second (MB/s).

The average OpenMP topology bandwidth is 112.682 MB/s, which is 90\% of the maximum theoretical bandwidth. The is consistent with 92.2\% of \emph{node-to-node} maximum theoretical bandwidth observed using the Linux \verb|iperf| command in Section ??.



The average serial topology bandwidth is 107.548 MB/s, which is 86\% of the maximum theoretical bandwidth. It is expected to observe a lower bandwidth with the serial topology due to the increased MPI process count compared to the the OpenMP topology. 



%
% SECTION
%
\section{HPCG Baseline}

The June 2020 HPCG List ranks 169 computer in order of HPCG benchmark performance.

Ranking number 1 is the Fugaku supercomputer.

Ranking 169 is the Spaceborne Computer. The Spaceborne Computer, onboard the International Space Station (ISS), is a 32 core system based on the Intel Xeon E5-2620 v4 8 core CPU, clocked at 2.1GHz, with an Infiniband interconnect.

An extract from the list for these two computers is in Table ??.

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
\hline
\textbf{HPCG} & \textbf{Name} & \textbf{Cores} & \textbf{HPL $\mathbf{R_{max}}$} & \textbf{HPCG}   & \textbf{Fraction} \\
\textbf{Rank} &      &       & \textbf{Pflops}        & \textbf{Pflops} & \textbf{of Peak}  \\
\hline
1 & Fugaku & 6,635,520 & 415.530  & 13.366 & 2.6\% \\
\hline
169 & Spaceborne & 32 & 0.001  & 0.000034 & 2.9\% \\
    & Computer   &    &        &          &       \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{Extract from June 2020 HPCG List.}}
\end{table}

For computers to be officially ranked in the HPCG List, the HPCG benchmark must be run for in excess of 30 minutes, using at least 25\% of available memory.

The HPCG benchmark results for the Aerin Cluster, obtained running the benchmark for 60 minutes using 75\% of available memory, are presented in Table ??.

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
\hline
\textbf{HPCG} & \textbf{Name} & \textbf{Cores} & \textbf{HPL $\mathbf{R_{max}}$} & \textbf{HPCG}   & \textbf{Fraction} \\
\textbf{Rank} &      &       & \textbf{Gflops}        & \textbf{Gflops} & \textbf{of Peak}  \\
\hline
- & OpenBLAS & 32 & 9.5525e+01 & 3.49084 & 1.8\% \\
  & Serial   &   &  &  &    \\
\hline
- & OpenBLAS & 32 & 9.6630e+01 & 2.90942 & 1.5\% \\
  & OpenMP   &   &  &  &    \\
\hline
- & BLIS     & 32 & 1.0341e+02 & 3.44246 & 1.8\% \\
  & Serial   &   &  &  &    \\
\hline
- & BLIS     & 32 & 1.0041e+02 & 2.95205 & 1.5\% \\
  & OpenMP   &   &  &  &    \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{Aerin Cluster HPCG Benchmark Results.}}
\end{table}


\subsubsection{Observations}


%
% SECTION
%
\section{Optimisations}

When running on a single node, as indicated in Figures 5.6, almost 100\% of CPU time is spent in \emph{user space}, i.e. running benchmark code. Therefore to gain benchmark performance improvement requires improvement to the architecture, algorithms, and/or supporting libraries, such as OpenBLAS and BLIS. Some work was done to improve OpenBLAS and BLIS performance on the Raspberry Pi 4, but this proved to be beyond the scope of this project (for the moment). 

\begin{figure}[]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{top-1node-serial.png}
		\caption{Serial Benchmark.}
		\label{fig:subim1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{top-1node-openmp.png}
		\caption{OpenMP Benchmark.}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{Single node \texttt{top} command output.} CPU time is almost exclusively spent in \emph{user space} (\texttt{us}) when running both serial and OpenMP benchmarks. Minimal time is spent \emph{idling} (\texttt{id}) or servicing software interrupts (\texttt{si}).}
\label{fig:image2}
\end{figure}

As seen in the 2 Node and Whole Cluster baseline results, when cores/nodes are networked together in cluster there is a reduction in performance per node. This is seen in Figure 5.7, where significant proportions of each node's CPU time is spent servicing \emph{software interrupts} generated by network \emph{receive} activity, and, in the case of OpenMP benchmarks, waiting for data.

\begin{figure}[]
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{top-8node-serial.png}
		\caption{Serial Benchmark.}
		\label{fig:subim2}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1.0\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{top-8node-openmp.png}
		\caption{OpenMP Benchmark.}
		\label{fig:subim2}
	\end{subfigure}
\caption{\textbf{8 node \texttt{top} command output.} Once networked together in a cluster, a significant proportion of each node's CPU time is spent in \emph{kernel space} (\texttt{sy}) when running both serial and OpenMP benchmarks, and \emph{idling} (\texttt{id}) in the OpenMP case. The images show observed worst case. Using \texttt{cat /proc/softirqs}, the software interrupt (\texttt{si}) CPU usage was observed to relate to network receive activity.} 
\label{fig:image2}
\end{figure}

The above observations suggested that network efficiency should be the focus of potential cluster optimisations.

The observations of Figure 5.7 can be summarised as follows:

\begin{enumerate}
\item The majority of the time in \emph{kernel space} is spent servicing software interrupts generated by network receive activity.
\item These interrupts are exclusively handled by CPU0 (core 0) of each node. This is seen using the Linux command \texttt{cat /proc/softirqs}.
\end{enumerate}

The strategy for improving network performance was therefore decided to be:

\begin{enumerate}
\item Reduce the numbers of interrupts - enable \emph{Interrupt Coalescing}
\item Distribute the interrupt servicing burden evenly across all node cores - enable \emph{Receive Packet Steering}
\item Improve core data locality - enable \emph{Receive Flow Steering}
\item Improve kernel processing throughput - implement a \emph{No Forced Preemption} kernel.
\item Improve network efficiency - implement a Jumbo Frames enabled kernel.
\end{enumerate}

The implementation of each of these optimisations is described in the following sections.


%
% SUB SECTION
%
\subsection{Interrupt Coalescing}

As discussed in Chapter 2, each packet received by a network interface generates a hardware interrupt. This results in a context switch to the kernel to process the packet. \emph{Interrupt coalescing} delays the raising of a hardware interrupt until a specified number of packets have been received, or a specified period of time has elapsed, thereby reducing the number of context switches. This potentially improves throughput and benchmark performance.

The Pi Cluster Tools \verb|interrupt-coalescing| tool enables \emph{Adaptive RX} interrupt coalescing. In \emph{Adaptive RX} interrupt coalescing the kernel actively manages the number of packets received, and the time elapsed, before raising a hardware interrupt on the network interface receive queue.

The results of running the \verb|linpack-profiler| tool with \emph{Adaptive RX} interrupt coalescing enabled are plotted in Figure ??.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{profile_interrupt_coalescing.pdf}
	\caption{Pi Cluster Tools \texttt{linpack-profiler} $R_{max}$ with \emph{Adaptive RX} interrupt coalescing enabled.}
	\label{fig:subim1}
\end{figure}

Using the value of the block size NB which achieved optimum performance running the \texttt{linpack-profiler} tool, the HPL benchmark results using 80\% of available memory are presented in Table ??. 

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
\hline
\multicolumn{5}{|c}{} & \multicolumn{2}{|c|}{$\mathbf{R_{max}}$ \textbf{(Gflops)}} \\
\hline
\textbf{BLAS} & \textbf{N} & \textbf{NB} & \textbf{P} & \textbf{Q} & \textbf{Baseline}  & \textbf{Adaptive RX}  \\
              &            &             &            &            &                    & \textbf{Coalescing} \\
\hline
OpenBLAS Serial & 52416 & 104 & 2 & 16 & 9.5525e+01 & 9.6078e+01 \\
\hline
OpenBLAS OpenMP & 52416 & 72 & 2 & 4 & 9.6630e+01 & 9.3222e+01 \\
\hline
BLIS Serial     & 52416 & 168 & 4 & 8 & 1.0341e+02 & 1.0205e+02 \\
\hline
BLIS OpenMP     & 52416 & 144 & 2 & 4 & 1.0041e+02 & 1.0582e+02 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPL $\mathbf{R_{max}}$ with \emph{Adaptive RX} interrupt coalescing enabled.}}
\end{table}

\subsubsection{Observations}

Observations and discussion...


%
% SUB SECTION
%
\subsection{Receive Packet Steering and Receive Flow Steering}

The results of running the \verb|linpack-profiler| tool with \emph{Receive Packet Steering} and \emph{Receive Flow Steering} enabled are plotted in Figure ??.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{profile_rps_rfs.pdf}
	\caption{Pi Cluster Tools \texttt{linpack-profiler} $R_{max}$ with Receive Packet Steering and Receive Flow Sterring enabled.}
	\label{fig:subim1}
\end{figure}

Using the value of the block size NB which achieved optimum performance running the \texttt{linpack-profiler} tool, the HPL benchmark results using 80\% of available memory are presented in Table ??. 

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
\hline
\multicolumn{5}{|c}{} & \multicolumn{2}{|c|}{$\mathbf{R_{max}}$ \textbf{(Gflops)}} \\
\hline
\textbf{BLAS} & \textbf{N} & \textbf{NB} & \textbf{P} & \textbf{Q} & \textbf{Baseline}  & \textbf{Adaptive RX}  \\
              &            &             &            &            &                    & \textbf{Coalescing} \\
\hline
OpenBLAS Serial & 52360 & 88 & 2 & 16 & 9.5525e+01 & 9.5672e+01 \\
\hline
OpenBLAS OpenMP & 52416 & 72 & 2 & 4 & 9.6630e+01 & 9.2954e+01 \\
\hline
BLIS Serial     & 52416 & 144 & 2 & 16 & 1.0341e+02 & 1.0117e+02 \\
\hline
BLIS OpenMP     & 51416 & 144 & 2 & 4 & 1.0041e+02 & 1.0597e+02 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{HPL $\mathbf{R_{max}}$ with \emph{Receive Packet Steering} and \emph{Receive Flow Steering} enabled.}}
\end{table}


\subsubsection{Observations}

Observations and discussion...



%
% SUB SECTION
%
\subsection{Kernel Preemption Model}

The Linux kernel has 3 Preemption Models, as discussed in Chapter 2:

\begin{itemize}
\item Preemptive
\item Voluntary Preemption
\item No Forced Preemption
\end{itemize}

For scientific computing workloads the \emph{No Forced Preemption} model should be used, as suggested by the \emph{help} accompanying the Linux kernel configuration utility:

\say{This is the traditional Linux preemption model, geared towards throughput. It will still provide good latencies most of the time, but there are no guarantees and occasional longer delays are possible. Select this option if you are building a kernel for a server or scientific/computation system, or if you want to maximise the raw processing power of the kernel, irrespective of scheduling latencies.}

The kernel installed by Ubuntu 20.04 LTS 64-bit uses the \emph{Voluntary Preemption} model. To use the \emph{No Forced Preemption} model the kernel needs to be recompiled. Detailed instructions on how to do this are included in the \emph{Kernel Build With No Forced Preemption} \verb|picluster| repository wiki page.

The Pi Cluster Tools \verb|linpack-profiler| tool was run with a \emph{No Forced Preemption} kernel. The results are plotted in Figure ??.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{profile_nopreempt.pdf}
	\caption{Pi Cluster Tools \texttt{linpack-profiler} $R_{max}$ with a \emph{No Forced Preemption} kernel.}
	\label{fig:subim1}
\end{figure}

Using the parameters which achieved optimum performance when running the \texttt{linpack-profiler} tool, the HPL benchmark results using 80\% of available memory are presented in Table ??. 

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
\hline
\multicolumn{5}{|c}{} & \multicolumn{2}{|c|}{$\mathbf{R_{max}}$ \textbf{(Gflops)}} \\
\hline
\textbf{BLAS} & \textbf{N} & \textbf{NB} & \textbf{P} & \textbf{Q} & \textbf{Baseline}  & \textbf{No Forced}  \\
              &            &             &            &            &                    & \textbf{Preemption} \\
\hline
OpenBLAS Serial & 52416 & 112 & 2 & 16 & 9.5525e+01 & 9.4729e+01 \\
\hline
OpenBLAS OpenMP & 52416 &  72 & 2 &  4 & 9.6630e+01 & 9.1107e+01 \\
\hline
BLIS Serial     & 52320 & 120 & 2 & 16 & 1.0341e+02 & 9.9248e+01 \\
\hline
BLIS OpenMP     & 52320 & 160 & 2 &  4 & 1.0041e+02 & 1.0694e+02 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}Comparison of the Baseline HPL $R_{max}$ with a \emph{No Forced Preemption} kernel.}
\end{table}


\subsubsection{Observations}

Observations and discussion...


%
% SUB SECTION
%
\subsection{Jumbo Frames}

The kernel installed by Ubuntu 20.04 LTS 64-bit uses the standard MTU size of 1500 bytes. To enable Jumbo Frames requires modifications to the kernel Ethernet network driver, and a recompilation of the kernel. The network driver modifications requires a high level of kernel development expertise, and proved to be only partially successful. Detailed instructions on how to do this are included in the \emph{Kernel Build With Jumbo Frames Support} project repository wiki page.

Figure 5.11 indicates the bandwidth improvement with increased MTU size.

\begin{figure}[H]
	\centering	
	\includegraphics[width=0.9\textwidth]{bandwidth_vs_mtu.pdf}
	\caption{\textbf{Node to Node Bandwidth.} The node-to-node bandwidth measured using the Linux \texttt{iperf} command.}
\end{figure}

The kernel with Jumbo Frame support, as implemented, was able to run HPL with a flat P x Q processor grid of 1 x 32 for serial benchmarks, and 1 x 8 for OpenMP benchmarks. However, for less flat processor grids, where the previous maximum performance had been observed, the network stack on one or more nodes became corrupted and the node became uncontactable. When this occurred, messages relating to network driver queues errors were observed in kernel message log.

\begin{figure}
	\centering	
	\includegraphics[width=0.9\textwidth]{gflops_vs_nodes_80_percent_memory_mtu_9000.pdf}
	\caption{\textbf{HPL $\mathbf{R_{max}}$ verus Node Count with MTU = 9000.}}
\end{figure}

Figure 5.12 indicates the potential increased performance with an expertly implemented MTU increase to 9000 bytes. In this figure, the increased performance using a flat P x Q grid of 1 x 32 is extrapolated to a 2 x 16 grid for a serial BLIS benchmark.


\subsubsection{Observations}

As indicated in Figure 5.12, expertly implemented Jumbo Frames support may yield a performance increase to 110 Gflops, a 7\% improvement.


%
% SECTION
%
\section{Performance Per Watt}

To determine the power usage of the Aerin Cluster a power meter was placed at the power outlet supplying the cluster. The power measured is presented in Table 5.16.

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c| } 
\hline
\textbf{Configuration} & \textbf{Power Usage} \\
                       & \textbf{(Watts}) \\
\hline
Router/firewall only                   & 5 \\
\hline
Network switch only                    & 4 \\
\hline
Router/firewall \& network switch only & 9 \\
\hline
Aerin Cluster at idle                  & 35\\
\hline
Aerin Cluster running benchmarks       & 70 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{Aerin Cluster Power Usage.} The 70 Watt power usage is the estimated average power usage observed when running serial and OpenMP benchmarks. The two Aerin Cluster power measurements include the router/firewall and network switch.}
\end{table}

When the Aerin Cluster is relocated to UCL, and the cluster is connected to the UCL internal network, the router/firewall will be redundant. It is therefore reasonable to state that the estimated average power usage for the Aerin Cluster 65 Watts when running benchmarks.

The maximum observed HPL performance is 103.41 Gflops.

Therefore, the Aerin Cluster's equivalent Green500 List performance is:

\begin{align}
Gflops/Watt &= \frac{103.41}{65} \\
            &= 1.591
\end{align}

The is equivalent to ranking 170 in the June 2020 Green500 List, as indicated in Table 5.17.

\begin{table}[H]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c| } 
\hline
\textbf{Rank} & \textbf{System} & \textbf{Cores} & \textbf{$\mathbf{R_{max}}$} & \textbf{Power}   & \textbf{Efficiency} \\
              &                 &                & \textbf{$\mathbf{TFlops}$} & \textbf{(KWatt)} & \textbf{(Gflops/Watt)} \\ 
\hline
169 & ISystem      & 97,920 & 1683.0 & 1,050 & 1.603 \\
    & Sugon TC6000 &        &        &       &       \\               
\hline
 -  & Aerin     & 32     & 0.10341 & 0.065 & 1.591 \\
    & Cluster   &        &        &       &       \\               
\hline
170 & MCSystem      & 74,400 & 1266.0 & 800 & 1.583 \\
    & Sugon TC6000 &        &        &       &       \\               
\hline
\end{tabular}
\end{center}
\caption{\label{tab:table-name}\textbf{Extract from June 2020 Green500 List.}}
\end{table}



%\begin{figure}[]
%	\begin{subfigure}{1.0\textwidth}
%		\centering
%		\includegraphics[width=0.5\textwidth]{power-netgear.jpg}
%		\caption{Network equipment only.}
%		\label{fig:subim1}
%	\end{subfigure}
%	\par\bigskip
%	\begin{subfigure}{1.0\textwidth}
%		\centering
%		\includegraphics[width=0.5\textwidth]{power-idle.jpg}
%		\caption{Aerin Cluster at idle.}
%		\label{fig:subim2}
%	\end{subfigure}
%	\par\bigskip
%	\begin{subfigure}{1.0\textwidth}
%		\centering
%		\includegraphics[width=0.5\textwidth]{power-benchmark.jpg}
%		\caption{Aerin Cluster running benchmarks.}
%		\label{fig:subim2}
%	\end{subfigure}
%\caption{\textbf{Aerin Cluster Power Usage.} Similar power usage was observed running either pure OpenMPI or hybrid OpenMPI/OpenMP benchmarks. The idle and benchmark power usage includes the network equipment.}
%\label{fig:image2}
%\end{figure}






