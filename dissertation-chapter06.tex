This chapter summarises the progress made in achieving the project aims, and then draws conclusions from the project as a whole.


%
% SECTION
%
\section{Project Aims}



%
% SUB SECTION
%
\subsection{Benchmark Performance}

\subsubsection{HPL}

The maximum HPL baseline performance of 103.41 Gflops was observed using the BLIS serial library. This is 53.86\% of the maximum theoretical performance ($R_{peak}$) of 192 Gflops. However, the Aerin Cluster was restricted to using 80\% of available memory. Taking this into account, 103.41 Gflops equates to 67.32\% of \emph{achievable} $R_{peak}$.


\subsubsection{HPCC}

The HPL and DGEMM results from the HPCC suite indicate similar performance to standalone HPL benchmark. This is to be expected. The STREAM sustained memory access benchmark suggests the Raspberry Pi 4 can utilise 80\% of the available memory bandwidth. And, the Network Bandwidth and Latency benchmark correlates closely with the performance observed when measuring node-to-node network bandwidth.


\subsubsection{HPCG}

Running the HPCG benchmark the Aerin Cluster achieved a maximum of 3.491 Gflops. In comparison, the 32 core Spaceborne Computer, onboard the International Space Station, achieved 34 Gflops. These HPCG benchmark results are 2.9\% and 1.8\% of $R_{peak}$ respectively.


%
% SUB SECTION
%
\subsection{Investigate Performance Optimisation}

There is no publicly available documentation for the Raspberry Pi Model B's network interface. And many of the network interface configuration options, normally available through the Linux \verb|ethtool| command, are not available, or are fixed and not configurable. This may be because the hardware does not support these configuration options, or because the current open source driver has yet to support these options.

It is therefore probably optimistic to expect the Raspberry Pi 4 Model B's network interface to support features such as interrupt coalescing, Receive Packet Steering and Receive Flow Steering. These features are normally to be found on server class hardware.

  


\subsubsection{Interrupt Coalescing}

It was observed that when networked together as the Aerin Cluster, each node spent a significant proportion of CPU time servicing interrupts generated by network packets arriving at the network interface.

To reduce the number of interrupts, and thereby reduce the number of context switches, Adaptive RX interrupt coalescing was enabled on each node's network interface. The effect of doing so was inconclusive. 


\subsubsection{RPS and RFS}

RPS (Receive Packet Steering) distributes network interrupt servicing evenly across the cores of a node. RFS (Receive Flow Steering) builds upon RPS to improve data locality by routing data directly to core consuming the data.

RPS was enabled and interrupt servicing was observed to be evenly distributed across the cores of each node. RFS was enabled but the effect of doing so was also inconclusive.


\subsubsection{No Forced Preemption kernel}

The default Linux kernel installed by Ubuntu 20.04 LTS uses the \emph{Voluntary Preemption} model. The suggested model for Scientific Computing workloads is the \emph{No Forced Preemption} model.

A new kernel was built using the \emph{No Forced Preemption} model. HPL benchmarks were then repeated with this kernel. Using 20\% of available memory an improvement in HPL performance was observed for OpenBLAS and BLIS in both serial and OpenMP versions. However, when using 80\% of memory an increase in HPL performance was only observed using the BLIS OpenMP library, a performance reduction was observed using the remaining BLAS libraries.

Therefore, the effect of using a No Forced Preemption kernel when solely running HPL benchmarks was inconclusive. This may not be the case for running other HPC workloads on the Aerin Cluster.


\subsubsection{Jumbo Frames}

With the default MTU of 1500 bytes, the Aerin Cluster node-to-node bandwidth was measured to be 922 Gbit/s, 92.2\% of the maximum theoretical bandwidth.

By amending the Ethernet network driver and recompiling the kernel to support Jumbo Frames, the node-to-node bandwidth was increased to 991 Gbit/s, 99.1\% of the theoretical maximum, with an MTU of 9000 bytes. This 7.5\% improvement in bandwidth was observed to result in improved HPL performance of 6.76\% for \emph{flat} P x Q processor grids.

However, amending the Ethernet network driver requires a high degree of network driver expertise. My  implementation of Jumbo Frames support proved to be insufficiently robust to use \emph{square} P x Q processor grids, where the maximum performance increase is likely to be observed.


%
% SUB SECTION
%
\subsection{Investigate Energy Efficiency}

By measuring the power consumed by whilst running HPL benchmarks it was determined that the Aerin Cluster can achieve an energy efficiency of 1.591 Gflops/Watt. This is equivalent to a ranking of 170 in the June 2020 Green500 List.  


%
% SECTION
%
\section{Conclusions}

Whilst drawing any conclusions from this project it should be kept in mind that the Raspberry Pi is a low cost, single-board computer, designed for the education and \emph{Maker} markets. It is not designed to be a HPC platform. Nevertheless, it is a very capable computer. And any design decisions to favour stability over exposing hardware intricacies (presumed) are the correct decisions for the intended markets.

\begin{itemize}
\item The combination of the Raspberry Pi 4 Model B and Ubuntu 20.04 LTS 64-bit is a very stable computing platform. The Aerin Cluster was able to run HPC benchmarks, utilising almost 100\% of CPU capacity, for many hours each day, for a number of months. On no occasion was a system failure observed.

\item The Raspberry Pi 4 is a relatively new computing platform. New features and enhancements are added regularly through updates to the EEPROM firmware. A recent addition is the ability to boot the Raspberry Pi 4 from a network, negating the need for local permanent storage. A firmware update in 2019 reduced the power consumption of the onboard memory and USB 3 controller. Such improvements in the future are likely to improve the performance and energy efficiency of the Raspberry Pi 4.

\item The Raspberry Pi 4 Compute Module is due to be released in 2020/2021. With only the BCM2711 SoC, and no additional hardware such as USB controllers drawing power, it will be interesting to benchmark the Gflops/Watt of this platform. It is possible that this platform could form the basis of a viable large scale HPC cluster.
\end{itemize}

